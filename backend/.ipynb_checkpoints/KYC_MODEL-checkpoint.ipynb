{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJFCB12kOWs2"
   },
   "source": [
    "# *Pipeline de Prétraitement*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "trqpb6n18NNj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, FunctionTransformer, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CENL5xvZOJaN"
   },
   "source": [
    "**Marquage des âges invalides**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "wDepEy5mwKHc"
   },
   "outputs": [],
   "source": [
    "def mark_invalid_ages_as_nan(X):\n",
    "    X[X <= 0] = pd.NA\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "CEr7mK-Qa_9f"
   },
   "outputs": [],
   "source": [
    "def encode_classes_binary(y, class_mapping):\n",
    "    # Convertir les étiquettes en codes numériques\n",
    "    y_encoded = y.map(class_mapping)\n",
    "    # Convertir les codes numériques en chaînes binaires\n",
    "    y_encoded_binary = y_encoded.apply(lambda x: f\"{x:02b}\")\n",
    "    return y_encoded_binary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIg37NVgOlkh"
   },
   "source": [
    "**Encodage et desencodage des labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "dPe4ibi_XHXg"
   },
   "outputs": [],
   "source": [
    "class CustomLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.label_encoders = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for col in X.columns:\n",
    "            le = LabelEncoder()\n",
    "            if X[col].dtype == 'object' or pd.api.types.is_bool_dtype(X[col]):\n",
    "                le.fit(X[col])\n",
    "                self.label_encoders[col] = le\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        for col, le in self.label_encoders.items():\n",
    "            if col in X.columns:  # Vérifier si la colonne est présente dans X\n",
    "                X_copy[col] = le.transform(X[col])\n",
    "        return X_copy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lower(x):\n",
    "    df = pd.DataFrame(x)\n",
    "    return df.map(lambda val: val.lower() if isinstance(val, str) else val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IP0yKj-XO88s"
   },
   "source": [
    "**Pretraitement des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "VocoxsvFwDlw"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data, target_column):\n",
    "    # Séparation des features et de la target\n",
    "    X = data.drop(target_column, axis=1)\n",
    "    y = data[target_column]\n",
    "\n",
    "    # Identification des colonnes numériques et catégorielles\n",
    "    numeric_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    categorical_features = X.select_dtypes(include=['object', 'bool']).columns\n",
    "\n",
    "    # Pipeline pour les features numériques\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('age_marker', FunctionTransformer(mark_invalid_ages_as_nan, validate=False)),  # Marque les âges non logiques comme NaN\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),  # Utilise KNN pour l'imputation\n",
    "        ('to_integer', FunctionTransformer(to_lower)),\n",
    "        ('scaler', MinMaxScaler())  # Normalise entre 0 et 1\n",
    "    ])\n",
    "\n",
    "    # Imputation et encodage LabelEncoder pour les features catégorielles\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        # Convert NumPy array to DataFrame for the CustomLabelEncoder\n",
    "        ('to_dataframe', FunctionTransformer(to_lower)),\n",
    "        ('label_encoder', CustomLabelEncoder()),\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    # Transformation des données\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ], remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Pipeline complet\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor)\n",
    "    ])\n",
    "\n",
    "    # Application du pipeline sur les données\n",
    "    X_preprocessed = pipeline.fit_transform(X)\n",
    "\n",
    "    # Encoder la cible (y) avec LabelEncoder\n",
    "    #le_y = LabelEncoder()\n",
    "   # y_encoded = le_y.fit_transform(y)  # Assurez-vous d'ajuster le label encoder ici\n",
    "    # Dictionnaire pour la conversion des classes en codes binaires\n",
    "    class_mapping = {\n",
    "        'RE': 0,  # 00\n",
    "        'RF': 1,  # 01\n",
    "        'RM': 2   # 10\n",
    "    }\n",
    "    y_encoded_binary = encode_classes_binary(y, class_mapping)\n",
    "    scaler = MinMaxScaler()\n",
    "    # y_preprocessed = scaler.fit_transform(y_encoded.reshape(-1, 1)).flatten()\n",
    "    y_preprocessed = y_encoded_binary\n",
    "    return X_preprocessed, y_preprocessed, pipeline, preprocessor\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4kKXZz2PIpH"
   },
   "source": [
    "### ***chargement des donnnées***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "tvmUU5BleECO",
    "outputId": "2ac69cb4-8fc1-4610-e90d-4bd75d116187"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valeurs uniques dans riskLevel (Y) :\n",
      "['RM' 'RE' 'RF']\n",
      "00\n",
      "riskLevel (Y)    01\n",
      "Name: 116, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>Activites_label</th>\n",
       "      <th>Produits</th>\n",
       "      <th>Relation</th>\n",
       "      <th>Pays</th>\n",
       "      <th>isPEP</th>\n",
       "      <th>famCode</th>\n",
       "      <th>VoieDeDistribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.191489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.723404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  nationality  gender  Activites_label  Produits  Relation   Pays  \\\n",
       "0  0.208333          0.9     1.0         0.000000  0.166667    0.6250  0.875   \n",
       "1  0.566667          0.9     1.0         0.127660  0.666667    0.0625  0.875   \n",
       "2  0.291667          0.9     1.0         0.127660  0.000000    0.5625  0.875   \n",
       "3  0.375000          0.9     1.0         0.127660  0.000000    0.5625  0.875   \n",
       "4  0.458333          0.9     1.0         0.000000  0.666667    0.0625  0.875   \n",
       "5  0.325000          0.9     1.0         0.191489  0.000000    0.5625  0.875   \n",
       "6  0.216667          0.9     0.0         0.723404  0.000000    0.5625  0.875   \n",
       "7  0.183333          0.9     1.0         0.382979  0.166667    0.8125  0.875   \n",
       "8  0.491667          0.9     0.0         0.723404  0.000000    0.5625  0.875   \n",
       "9  0.491667          0.9     1.0         0.127660  0.000000    0.5625  0.875   \n",
       "\n",
       "   isPEP   famCode  VoieDeDistribution  \n",
       "0    0.0  0.000000                 0.0  \n",
       "1    0.0  0.666667                 0.0  \n",
       "2    0.0  0.666667                 0.0  \n",
       "3    0.0  0.000000                 0.0  \n",
       "4    0.0  0.666667                 0.0  \n",
       "5    0.0  0.666667                 1.0  \n",
       "6    0.0  0.000000                 0.0  \n",
       "7    0.0  0.000000                 0.0  \n",
       "8    0.0  1.000000                 0.0  \n",
       "9    0.0  0.666667                 0.0  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger les données depuis un fichier CSV\n",
    "file_path = 'clients.csv'\n",
    "data = pd.read_csv(file_path, delimiter=';')\n",
    "data.dtypes\n",
    "\n",
    "# Spécifier la colonne cible pour la prédiction\n",
    "target_column = 'riskLevel (Y)'\n",
    "\n",
    "print(\"Valeurs uniques dans riskLevel (Y) :\")\n",
    "print(data['riskLevel (Y)'].unique())\n",
    "\n",
    "# Prétraiter les données\n",
    "X_preprocessed, y_preprocessed, pipeline, preprocessor = preprocess_data(data, target_column)\n",
    "print(y_preprocessed[80])\n",
    "data_df = pd.DataFrame(data, columns=data.drop(target_column, axis=1).columns)\n",
    "X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=data.drop(target_column, axis=1).columns)\n",
    "y_preprocessed_df = pd.DataFrame(y_preprocessed)\n",
    "print(y_preprocessed_df.iloc[116])\n",
    "X_preprocessed_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jZZwLIBPe83"
   },
   "source": [
    "## ***Entraînement et Évaluation des Modèles***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kq5pIK-mPvO5"
   },
   "source": [
    "**Modèles de Classification :**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "vaNXRiQhJUsw"
   },
   "outputs": [],
   "source": [
    "# Split des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y_preprocessed, test_size=0.3, random_state=42)\n",
    "\n",
    "# Définition des modèles et de leurs grilles de paramètres\n",
    "models = {\n",
    "    \"Gradient Boosting\": {\n",
    "        \"model\": GradientBoostingClassifier(random_state=42),\n",
    "        \"params\": {\n",
    "            'classifier__n_estimators': [50, 100],\n",
    "            'classifier__learning_rate': [0.01, 0.1],\n",
    "            'classifier__max_depth': [3, 5],\n",
    "            'classifier__min_samples_split': [2, 5],\n",
    "            'classifier__min_samples_leaf': [1, 2]\n",
    "        }\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"model\": RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "        \"params\": {\n",
    "            'classifier__n_estimators': [50, 100],\n",
    "            'classifier__max_depth': [None, 10, 20],\n",
    "            'classifier__min_samples_split': [2, 5],\n",
    "            'classifier__min_samples_leaf': [1, 2],\n",
    "            'classifier__bootstrap': [True, False]\n",
    "        }\n",
    "    },\n",
    "    \"Support Vector Machine\": {\n",
    "        \"model\": SVC(class_weight='balanced', random_state=42),\n",
    "        \"params\": {\n",
    "            'classifier__C': [0.1, 1.0, 10.0],\n",
    "            'classifier__kernel': ['linear', 'rbf']\n",
    "        }\n",
    "    },\n",
    "    \"k-Nearest Neighbors\": {\n",
    "        \"model\": KNeighborsClassifier(),\n",
    "        \"params\": {\n",
    "            'classifier__n_neighbors': [3, 5, 7],\n",
    "            'classifier__weights': ['uniform', 'distance']\n",
    "        }\n",
    "    },\n",
    "    \"Neural Network\": {\n",
    "        \"model\": MLPClassifier(max_iter=200, random_state=42),\n",
    "        \"params\": {\n",
    "            'classifier__hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "            'classifier__activation': ['relu', 'tanh']\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qs88No4pPyjt"
   },
   "source": [
    "Equilibrage des classes avec SMOTE et Optimisation des paramétres avec GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Npolh3VUJW7C",
    "outputId": "707ba921-3c2c-46cd-e587-e385513009c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient Boosting...\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "Best parameters for Gradient Boosting: {'classifier__learning_rate': 0.1, 'classifier__max_depth': 5, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}\n",
      "Best score for Gradient Boosting: 0.9882128618478072\n",
      "Accuracy for Gradient Boosting: 0.9886777193691872\n",
      "Classification Report for Gradient Boosting:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          RE       0.68      0.72      0.70        29\n",
      "          RF       0.91      0.99      0.95        95\n",
      "          RM       1.00      0.99      0.99      2349\n",
      "\n",
      "    accuracy                           0.99      2473\n",
      "   macro avg       0.86      0.90      0.88      2473\n",
      "weighted avg       0.99      0.99      0.99      2473\n",
      "\n",
      "\n",
      "F1 Score for Gradient Boosting: 0.9888686440439916\n",
      "Recall Score for Gradient Boosting: 0.9886777193691872\n",
      "Precision Score for Gradient Boosting: 0.9892057066051324\n",
      "\n",
      "Training Random Forest...\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "Best parameters for Random Forest: {'classifier__bootstrap': True, 'classifier__max_depth': 20, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 100}\n",
      "Best score for Random Forest: 0.984919396775871\n",
      "Accuracy for Random Forest: 0.9874646178730287\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          RE       0.69      0.69      0.69        29\n",
      "          RF       0.89      0.98      0.93        95\n",
      "          RM       1.00      0.99      0.99      2349\n",
      "\n",
      "    accuracy                           0.99      2473\n",
      "   macro avg       0.86      0.89      0.87      2473\n",
      "weighted avg       0.99      0.99      0.99      2473\n",
      "\n",
      "\n",
      "F1 Score for Random Forest: 0.9875714595104731\n",
      "Recall Score for Random Forest: 0.9874646178730287\n",
      "Precision Score for Random Forest: 0.9878324364676973\n",
      "\n",
      "Training Support Vector Machine...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best parameters for Support Vector Machine: {'classifier__C': 10.0, 'classifier__kernel': 'rbf'}\n",
      "Best score for Support Vector Machine: 0.9088230195874502\n",
      "Accuracy for Support Vector Machine: 0.883946623534169\n",
      "Classification Report for Support Vector Machine:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          RE       0.12      0.83      0.21        29\n",
      "          RF       0.45      0.95      0.61        95\n",
      "          RM       1.00      0.88      0.94      2349\n",
      "\n",
      "    accuracy                           0.88      2473\n",
      "   macro avg       0.52      0.89      0.59      2473\n",
      "weighted avg       0.97      0.88      0.91      2473\n",
      "\n",
      "\n",
      "F1 Score for Support Vector Machine: 0.9148488363209424\n",
      "Recall Score for Support Vector Machine: 0.883946623534169\n",
      "Precision Score for Support Vector Machine: 0.9651097588218495\n",
      "\n",
      "Training k-Nearest Neighbors...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best parameters for k-Nearest Neighbors: {'classifier__n_neighbors': 3, 'classifier__weights': 'distance'}\n",
      "Best score for k-Nearest Neighbors: 0.9627318426070376\n",
      "Accuracy for k-Nearest Neighbors: 0.9692680954306511\n",
      "Classification Report for k-Nearest Neighbors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          RE       0.37      0.62      0.46        29\n",
      "          RF       0.77      0.93      0.84        95\n",
      "          RM       0.99      0.98      0.98      2349\n",
      "\n",
      "    accuracy                           0.97      2473\n",
      "   macro avg       0.71      0.84      0.76      2473\n",
      "weighted avg       0.98      0.97      0.97      2473\n",
      "\n",
      "\n",
      "F1 Score for k-Nearest Neighbors: 0.9719681935683451\n",
      "Recall Score for k-Nearest Neighbors: 0.9692680954306511\n",
      "Precision Score for k-Nearest Neighbors: 0.9761572543866852\n",
      "\n",
      "Training Neural Network...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best parameters for Neural Network: {'classifier__activation': 'relu', 'classifier__hidden_layer_sizes': (50, 50)}\n",
      "Best score for Neural Network: 0.9616918010053735\n",
      "Accuracy for Neural Network: 0.9433885968459361\n",
      "Classification Report for Neural Network:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          RE       0.25      0.69      0.37        29\n",
      "          RF       0.58      0.89      0.70        95\n",
      "          RM       0.99      0.95      0.97      2349\n",
      "\n",
      "    accuracy                           0.94      2473\n",
      "   macro avg       0.61      0.84      0.68      2473\n",
      "weighted avg       0.97      0.94      0.95      2473\n",
      "\n",
      "\n",
      "F1 Score for Neural Network: 0.9522534383852188\n",
      "Recall Score for Neural Network: 0.9433885968459361\n",
      "Precision Score for Neural Network: 0.9670081931378621\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emnam\\anaconda3\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Dictionnaire pour la conversion des classes en codes binaires\n",
    "class_mapping = {\n",
    "    'RE': 0,  # 00\n",
    "    'RF': 1,  # 01\n",
    "    'RM': 2   # 10\n",
    "}\n",
    "\n",
    "# Entraînement et évaluation des modèles\n",
    "for model_name, model_info in models.items():\n",
    "    pipeline = ImbPipeline(steps=[\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', model_info['model'])\n",
    "    ])\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=pipeline,\n",
    "                               param_grid=model_info['params'],\n",
    "                               cv=3,\n",
    "                               scoring='accuracy',\n",
    "                               n_jobs=-1,\n",
    "                               verbose=2)\n",
    "\n",
    "    print(f\"Training {model_name}...\")\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(f\"Best parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best score for {model_name}: {grid_search.best_score_}\")\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    print(f\"Accuracy for {model_name}: {accuracy_score(y_test, y_pred)}\")\n",
    "    print(f\"Classification Report for {model_name}:\\n{classification_report(y_test, y_pred, target_names=class_mapping.keys())}\\n\")\n",
    "    print(f\"F1 Score for {model_name}: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "    print(f\"Recall Score for {model_name}: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "    print(f\"Precision Score for {model_name}: {precision_score(y_test, y_pred, average='weighted')}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "negn6haO3jRP",
    "outputId": "c43d8ae0-a030-469e-d4c1-fd2433a77c93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.98584715\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          RE       0.64      0.72      0.68        29\n",
      "          RF       0.88      0.98      0.93        95\n",
      "          RM       1.00      0.99      0.99      2349\n",
      "\n",
      "    accuracy                           0.99      2473\n",
      "   macro avg       0.84      0.90      0.87      2473\n",
      "weighted avg       0.99      0.99      0.99      2473\n",
      "\n",
      "F1 Score: 0.99\n",
      "Recall Score: 0.99\n",
      "Precision Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the original data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y_preprocessed, test_size=0.3, random_state=42)\n",
    "# Create SMOTE object\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "gb_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on test set: {accuracy:.8f}\")\n",
    "\n",
    "# Print Classification Report\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred, target_names=class_mapping.keys())}\")\n",
    "\n",
    "# Calculate and print F1 Score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# Calculate and print Recall Score\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Recall Score: {recall:.2f}\")\n",
    "\n",
    "# Calculate and print Precision Score\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(f\"Precision Score: {precision:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeHux6x3cuW_"
   },
   "source": [
    " Après avoir comparé les performances des différents modèles de classification (Gradient Boosting, Random Forest, SVM, k-Nearest Neighbors, et Neural Network), il est clair que chaque modèle présente des forces et des faiblesses. Les modèles Gradient Boosting et Random Forest montrent de bonnes performances globales avec des précisions de 98.79% et 98.38% respectivement. Cependant, tous les modèles éprouvent des difficultés à bien prédire la classe RE, qui est cruciale pour la classification des risques. => **nécessite d'empilement.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7Axol0_P_ZA"
   },
   "source": [
    "## ***Classificateur d'Empilement (Stacking)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nD_V-Nsli8LR",
    "outputId": "52d33082-ac07-48c8-d62b-f21dfb014e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9943388596845936\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          RE       0.88      0.76      0.81        29\n",
      "          RF       0.97      0.99      0.98        95\n",
      "          RM       1.00      1.00      1.00      2349\n",
      "\n",
      "    accuracy                           0.99      2473\n",
      "   macro avg       0.95      0.92      0.93      2473\n",
      "weighted avg       0.99      0.99      0.99      2473\n",
      "\n",
      "F1 Score: 0.994198722881669\n",
      "Recall Score: 0.9943388596845936\n",
      "Precision Score: 0.9941725278142884\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define base models\n",
    "base_models = [\n",
    "    ('gb', GradientBoostingClassifier(learning_rate=0.1, max_depth=5, min_samples_leaf=1, min_samples_split=5, n_estimators=100, random_state=42)),\n",
    "    ('rf', RandomForestClassifier(bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50, random_state=42))\n",
    "]\n",
    "\n",
    "# Define the meta model\n",
    "meta_model = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "# Define the stacking classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the stacking classifier\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred, target_names=class_mapping.keys())}\")\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"Recall Score: {recall_score(y_test, y_pred, average='weighted')}\")\n",
    "print(f\"Precision Score: {precision_score(y_test, y_pred, average='weighted')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age nationality gender  \\\n",
      "0      26     Tunisie  homme   \n",
      "1      69     Tunisie  homme   \n",
      "2      36     Tunisie  homme   \n",
      "3      46     Tunisie  homme   \n",
      "4      56     Tunisie  homme   \n",
      "...   ...         ...    ...   \n",
      "8237   38     Tunisie  homme   \n",
      "8238   35     Tunisie  homme   \n",
      "8239   63     Tunisie  homme   \n",
      "8240   44     Tunisie  femme   \n",
      "8241   34     Tunisie  homme   \n",
      "\n",
      "                                        Activites_label        Produits  \\\n",
      "0                  ADMINISTRATIONS  FONCTIONS PUBLIQUES  Autres risques   \n",
      "1                                       AUTRES SERVICES      Prevoyance   \n",
      "2                                       AUTRES SERVICES      AUTOMOBILE   \n",
      "3                                       AUTRES SERVICES      AUTOMOBILE   \n",
      "4                  ADMINISTRATIONS  FONCTIONS PUBLIQUES      Prevoyance   \n",
      "...                                                 ...             ...   \n",
      "8237               ADMINISTRATIONS  FONCTIONS PUBLIQUES      AUTOMOBILE   \n",
      "8238               ADMINISTRATIONS  FONCTIONS PUBLIQUES  Autres risques   \n",
      "8239                                    AUTRES SERVICES      AUTOMOBILE   \n",
      "8240               ADMINISTRATIONS  FONCTIONS PUBLIQUES  Autres risques   \n",
      "8241  MEDECINS PHARMACIENS  AUTRES AUXILIAIRES DE SANTE      Prevoyance   \n",
      "\n",
      "           Relation     Pays  isPEP famCode VoieDeDistribution  \n",
      "0            Membre  TUNISIE  False       C            Agences  \n",
      "1          Adherent  TUNISIE  False       M            Agences  \n",
      "2     lui-elle-meme  TUNISIE  False       M            Agences  \n",
      "3     lui-elle-meme  TUNISIE  False       C            Agences  \n",
      "4          Adherent  TUNISIE  False       M            Agences  \n",
      "...             ...      ...    ...     ...                ...  \n",
      "8237       Adherent  TUNISIE  False       C            Agences  \n",
      "8238       Adherent  TUNISIE  False       M            Agences  \n",
      "8239  lui-elle-meme  TUNISIE  False       M            Agences  \n",
      "8240       Adherent  TUNISIE  False       M            Agences  \n",
      "8241  lui-elle-meme  TUNISIE  False       M            Agences  \n",
      "\n",
      "[8242 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sjdq-ol5dGER"
   },
   "source": [
    " Cette approche a permis d'atteindre une précision globale de 99.41%, surpassant les performances de chaque modèle individuel et offrant une solution plus robuste et fiable pour la classification des niveaux de risque."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s9IbXa_6QNFE"
   },
   "source": [
    "### Calcul du Coefficient de Risque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_ZTWx7NQXiR"
   },
   "source": [
    "Identification des valeurs de caractéristiques à haut risque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4m-c-7urf8vq",
    "outputId": "81b815ad-672c-4ed7-f784-9072c65be5a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes du modèle stacking classificateur : ['00' '01' '10']\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes du modèle stacking classificateur :\", stacking_clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fm4i4k3fjX9l",
    "outputId": "1aae09b8-8be9-4b80-c06c-52171af20a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes du modèle GB : ['00' '01' '10']\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes du modèle GB :\", gb_clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQDrwVgqgkzQ",
    "outputId": "233003ce-6d52-4876-c502-6491d87ed60d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient de risque pour Produits = Epargne: 98.39%\n",
      "Suggestion de risque associée : RE (Risque Élevé)\n"
     ]
    }
   ],
   "source": [
    "def calculate_risk_coefficient(model, X_preprocessed_df, y_preprocessed_df, data_df, feature_name, feature_value):\n",
    "    # Convertir feature_value au même type que dans data_df\n",
    "    feature_value = pd.Series([feature_value]).astype(data_df[feature_name].dtype)[0]\n",
    "\n",
    "    # Trouver l'indice de feature_value dans les données originales\n",
    "    if feature_value in data_df[feature_name].values:\n",
    "        index = data_df[data_df[feature_name] == feature_value].index[0]\n",
    "    else:\n",
    "        raise ValueError(f\"La valeur '{feature_value}' n'a pas été trouvée dans la colonne '{feature_name}' de data_df\")\n",
    "\n",
    "    # Prédire les probabilités en utilisant le modèle de stacking\n",
    "    probas = model.predict_proba([X_preprocessed_df.iloc[index]])\n",
    "\n",
    "    # Trouver l'indice de la classe avec la probabilité la plus élevée\n",
    "    predicted_class_index = np.argmax(probas[0])\n",
    "\n",
    "    # Trouver la classe prédite\n",
    "    predicted_class = model.classes_[predicted_class_index]\n",
    "\n",
    "    # Calculer le coefficient de risque en pourcentage basé sur la proportion de la classe prédite\n",
    "    risk_percentage = probas[0][predicted_class_index] * 100\n",
    "\n",
    "    # Déterminer le niveau de risque associé en fonction du coefficient de risque\n",
    "    if predicted_class == '00':\n",
    "        risk_suggestion = 'RE (Risque Élevé)'\n",
    "    elif predicted_class == '01':\n",
    "        risk_suggestion = 'RF (Risque Faible)'\n",
    "    elif predicted_class == '10':\n",
    "        risk_suggestion = 'RM (Risque Moyen)'\n",
    "    else:\n",
    "        risk_suggestion = 'Inconnu'\n",
    "\n",
    "    return risk_percentage, risk_suggestion\n",
    "\n",
    "# Utilisation de la fonction pour calculer le taux de risque en pourcentage et suggestion de risque\n",
    "feature_name = 'Produits'\n",
    "feature_value = 'Epargne'  # Remplacez par la valeur réelle que vous souhaitez interroger\n",
    "risk_percentage, risk_suggestion = calculate_risk_coefficient(gb_clf, X_preprocessed_df, y_preprocessed_df, data_df, feature_name, feature_value)\n",
    "\n",
    "print(f\"Coefficient de risque pour {feature_name} = {feature_value}: {risk_percentage:.2f}%\")\n",
    "print(f\"Suggestion de risque associée : {risk_suggestion}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E3hZMkCbjzdO",
    "outputId": "2a67caf7-58f2-4371-a058-ce2d5c93f031"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Coefficient de risque de haut risque ===\n",
      "=== Pour la colonne 'age' ===\n",
      "Valeur: 26 - Risque: 99.88% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 69 - Risque: 91.74% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 36 - Risque: 99.70% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 46 - Risque: 99.61% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 56 - Risque: 99.26% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 40 - Risque: 97.72% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 27 - Risque: 99.62% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 23 - Risque: 99.89% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 60 - Risque: 99.58% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 41 - Risque: 99.81% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 31 - Risque: 99.09% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 55 - Risque: 77.94% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 59 - Risque: 98.67% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 39 - Risque: 98.96% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 25 - Risque: 82.40% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 47 - Risque: 98.78% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 21 - Risque: 97.30% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 0 - Risque: 99.33% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 30 - Risque: 99.36% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 71 - Risque: 99.35% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 24 - Risque: 99.71% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 53 - Risque: 99.76% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 34 - Risque: 99.87% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 29 - Risque: 80.14% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 32 - Risque: 97.91% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 42 - Risque: 81.97% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 37 - Risque: 99.56% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 52 - Risque: 99.57% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 43 - Risque: 99.81% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 70 - Risque: 99.65% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 28 - Risque: 99.87% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 64 - Risque: 88.91% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 61 - Risque: 98.67% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 50 - Risque: 93.28% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 68 - Risque: 99.35% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 54 - Risque: 87.72% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 33 - Risque: 98.69% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 10 - Risque: 98.69% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 11 - Risque: 98.69% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 38 - Risque: 98.12% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 48 - Risque: 99.79% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 44 - Risque: 99.33% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 19 - Risque: 99.51% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 66 - Risque: 98.69% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 35 - Risque: 99.32% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 45 - Risque: 95.01% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 9 - Risque: 98.96% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 13 - Risque: 99.41% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 20 - Risque: 99.71% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 65 - Risque: 99.57% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 72 - Risque: 99.87% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 62 - Risque: 99.05% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 22 - Risque: 99.71% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 58 - Risque: 98.74% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 74 - Risque: 99.35% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 2 - Risque: 82.84% - Suggestion: RE (Risque Élevé)\n",
      "Valeur: 67 - Risque: 99.00% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 51 - Risque: 77.54% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 77 - Risque: 99.75% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 63 - Risque: 98.67% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 57 - Risque: 99.56% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 3 - Risque: 99.41% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 73 - Risque: 99.65% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 79 - Risque: 99.75% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 81 - Risque: 99.13% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 18 - Risque: 99.71% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 80 - Risque: 99.92% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 4 - Risque: 99.80% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 90 - Risque: 99.35% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 6 - Risque: 73.87% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 16 - Risque: 99.41% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 84 - Risque: 99.86% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 15 - Risque: 98.96% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 17 - Risque: 98.69% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 78 - Risque: 99.71% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 12 - Risque: 99.87% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 93 - Risque: 99.75% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 75 - Risque: 99.87% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 76 - Risque: 99.76% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 14 - Risque: 99.80% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 8 - Risque: 99.80% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 1 - Risque: 99.41% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 5 - Risque: 99.41% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 91 - Risque: 98.94% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 89 - Risque: 99.75% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 92 - Risque: 99.35% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 83 - Risque: 97.22% - Suggestion: RE (Risque Élevé)\n",
      "Valeur: 82 - Risque: 99.79% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 94 - Risque: 99.92% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 86 - Risque: 99.92% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 7 - Risque: 98.96% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 95 - Risque: 99.35% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 121 - Risque: 99.07% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: 87 - Risque: 94.39% - Suggestion: RM (Risque Moyen)\n",
      "\n",
      "=== Pour la colonne 'nationality' ===\n",
      "Valeur: Tunisie - Risque: 99.88% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Libye - Risque: 97.87% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: France - Risque: 99.55% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Gabon - Risque: 99.36% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Maroc - Risque: 87.72% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Jordanie - Risque: 78.39% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Liban - Risque: 80.11% - Suggestion: RE (Risque Élevé)\n",
      "Valeur: Yemen - Risque: 89.82% - Suggestion: RE (Risque Élevé)\n",
      "Valeur: Mauritanie - Risque: 97.87% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Algerie - Risque: 99.62% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Tokelau - Risque: 99.75% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Italie - Risque: 99.84% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Turquie - Risque: 98.49% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Afrique du Sud - Risque: 98.86% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Irak - Risque: 97.61% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Cote dIvoire - Risque: 99.78% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Syrie - Risque: 99.55% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Arabie Saoudite - Risque: 97.04% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Tchad - Risque: 97.43% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Cameroun - Risque: 97.99% - Suggestion: RF (Risque Faible)\n",
      "\n",
      "=== Pour la colonne 'gender' ===\n",
      "Valeur: homme - Risque: 99.88% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: femme - Risque: 99.62% - Suggestion: RM (Risque Moyen)\n",
      "\n",
      "=== Pour la colonne 'Activites_label' ===\n",
      "Valeur: ADMINISTRATIONS  FONCTIONS PUBLIQUES - Risque: 99.88% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: AUTRES SERVICES - Risque: 91.74% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: COMMERCES NEGOCES DISTRIBUTIONS  LIVRAISON - Risque: 97.72% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: SANS ACTIVITES PECUNIAIRES  - Risque: 99.62% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: ETUDES SCIENTIFIQUES TECHNIQUES CONSEILS  - Risque: 99.89% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: AGRICULTURES ELEVAGES  CHASSE - Risque: 99.76% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: COMPTABILITES AUDITS  GESTIONS  - Risque: 99.56% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: ARTS COMMUNICATIONS  MULTIMEDIAS  - Risque: 99.87% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: INDUSTRIES BOIS  AMEUBLEMENTS  - Risque: 99.36% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: MEDECINS PHARMACIENS  AUTRES AUXILIAIRES DE SANTE - Risque: 94.34% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: BANQUES ASSURANCES  ETABLISSEMENTS FINANCIERS - Risque: 92.98% - Suggestion: RE (Risque Élevé)\n",
      "Valeur: TRANSPORTS ROUTIERS FERROVIAIRES SERVICES CONNEXES  - Risque: 99.56% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: TRANSPORTS MARITIMES SERVICES CONNEXES - Risque: 99.58% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: ENSEIGNEMENTS  ACTIVITES CULTURELLES - Risque: 91.70% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: SERVICES  MATERIELS INFORMATIQUES  - Risque: 99.62% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: ARTISANATS  - Risque: 99.41% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: INDUSTRIES INFORMATIQUES  - Risque: 98.96% - Suggestion: RF (Risque Faible)\n",
      "Valeur: CONSTRUCTIONS TRAVAUX DINSTALLATIONS  DE BATIMENT  - Risque: 99.65% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: ENVIRONNEMENTS  - Risque: 91.53% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: TRANSPORTS AERIENS  SERVICES CONNEXES  - Risque: 93.22% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: TOURISMES HOTELLERIES  RESTAURATIONS  - Risque: 99.56% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: EMBALLAGES CONDITIONNEMENTS  ENTREPOSAGES - Risque: 99.12% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: PROGRAMATION TRAITEMENTS  CONSEILS BASES DE DONNEES - Risque: 99.27% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: BOULANGERIE  PATISSERIES - Risque: 99.50% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: EDITIONS  IMPRIMERIES  - Risque: 99.32% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: ASSOCIATIONS ORGANISMES POLITIQUES PATRONALS  PROFESSIONNELS - Risque: 99.51% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: ENERGIES ELECTRICITESPETROLES GAZ MINERAIS  MATIERES PREMIERES - Risque: 88.45% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: SECURITE ENQUETES  PROTECTION CIVILE  - Risque: 94.24% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: LOISIRS  SPORTS  - Risque: 96.45% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: INDUSTRIES ALIMENTAIRES  AGROALIMENTAIRES  - Risque: 82.14% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: SERVICES COURTAGES INTERMEDIATIONS  SOUS-TRAITANCE  - Risque: 99.50% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: INDUSTRIES MECANIQUES - Risque: 99.24% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: SERVICES POSTES  TELECOMMUNICATIONS  - Risque: 98.28% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: INDUSTRIES AERONAUTIQUES FEVORROVIAIRES  NAVALES  - Risque: 91.26% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: SERVICES IMMOBILIERS  - Risque: 99.61% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: DROITS  ACTIVITES JURIDIQUES - Risque: 91.71% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: INDUSTRIES PHARMACEUTIQUES  - Risque: 85.77% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: INDUSTRIES APPAREILS  MACHINES ELECTRIQUES - Risque: 99.38% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: SERVICES LOCATIONS  - Risque: 98.98% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: SERVICES SOCIAUX  - Risque: 99.51% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: INDUSTRIES TEXTILES HABILLEMENTS  CHAUSSURES  - Risque: 99.38% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: INDUSTRIES CHIMIQUES  AGROCHIMIQUES  - Risque: 99.31% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: SOINS  BIEN ETRE - Risque: 99.55% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: SERVICES REPARATIONS  - Risque: 91.05% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: INDUSTRIES CAOUTCHOUCS  PLASTIQUES - Risque: 99.43% - Suggestion: RM (Risque Moyen)\n",
      "\n",
      "=== Pour la colonne 'Produits' ===\n",
      "Valeur: Autres risques - Risque: 99.88% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Prevoyance - Risque: 91.74% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: AUTOMOBILE - Risque: 99.70% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: SANTE - Risque: 82.40% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Epargne - Risque: 98.39% - Suggestion: RE (Risque Élevé)\n",
      "Valeur: INCENDIE - Risque: 92.98% - Suggestion: RE (Risque Élevé)\n",
      "Valeur: Transport - Risque: 88.90% - Suggestion: RE (Risque Élevé)\n",
      "\n",
      "=== Pour la colonne 'Relation' ===\n",
      "Valeur: Membre - Risque: 99.88% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Adherent - Risque: 91.74% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: lui-elle-meme - Risque: 99.70% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Personnel - Risque: 99.89% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Actionnaire ou associe - Risque: 99.03% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: enfant - Risque: 74.09% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Representant legal - Risque: 99.93% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: tuteur - Risque: 100.00% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: filiale - Risque: 98.94% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Fondateur - Risque: 98.34% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: mère - Risque: 99.58% - Suggestion: RM (Risque Moyen)\n",
      "\n",
      "=== Pour la colonne 'Pays' ===\n",
      "Valeur: TUNISIE - Risque: 99.88% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: LYBIE - Risque: 86.73% - Suggestion: RE (Risque Élevé)\n",
      "Valeur: JORDANIE - Risque: 78.39% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: LIBAN - Risque: 80.11% - Suggestion: RE (Risque Élevé)\n",
      "Valeur: YEMEN - Risque: 89.82% - Suggestion: RE (Risque Élevé)\n",
      "Valeur: MAROC - Risque: 82.65% - Suggestion: RE (Risque Élevé)\n",
      "Valeur: PORTUGAL - Risque: 70.14% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: FRANCE - Risque: 99.48% - Suggestion: RF (Risque Faible)\n",
      "\n",
      "=== Pour la colonne 'isPEP' ===\n",
      "Valeur: False - Risque: 99.88% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: True - Risque: 99.71% - Suggestion: RM (Risque Moyen)\n",
      "\n",
      "=== Pour la colonne 'famCode' ===\n",
      "Valeur: C - Risque: 99.88% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: M - Risque: 91.74% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: V - Risque: 99.58% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: D - Risque: 95.01% - Suggestion: RM (Risque Moyen)\n",
      "\n",
      "=== Pour la colonne 'VoieDeDistribution' ===\n",
      "Valeur: Agences - Risque: 99.88% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Courtiers - Risque: 97.72% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Bureaux directs - Risque: 82.40% - Suggestion: RM (Risque Moyen)\n",
      "Valeur: Bancassurance - Risque: 98.42% - Suggestion: RM (Risque Moyen)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_risk_coefficients(model, X_preprocessed_df, y_preprocessed_df, data_df, risk_threshold=70):\n",
    "    # Initialisation d'un dictionnaire pour stocker les résultats de haut risque\n",
    "    high_risk_coefficients = {}\n",
    "\n",
    "    # Itération sur toutes les colonnes de X_preprocessed_df\n",
    "    for feature_name in X_preprocessed_df.columns:\n",
    "        feature_values = data_df[feature_name].unique()\n",
    "        feature_high_risk_coefficients = {}\n",
    "\n",
    "        # Calculer le coefficient de risque pour chaque valeur de la colonne\n",
    "        for feature_value in feature_values:\n",
    "            try:\n",
    "                risk_percentage, risk_suggestion = calculate_risk_coefficient(model, X_preprocessed_df, y_preprocessed_df, data_df, feature_name, feature_value)\n",
    "\n",
    "                # Filtrer seulement les valeurs avec un risque élevé\n",
    "                if risk_percentage >= risk_threshold:\n",
    "                    feature_high_risk_coefficients[feature_value] = {\n",
    "                        'risk_percentage': risk_percentage,\n",
    "                        'risk_suggestion': risk_suggestion\n",
    "                    }\n",
    "            except ValueError as e:\n",
    "                print(f\"Erreur : {e}\")\n",
    "\n",
    "        # Stocker les résultats de haut risque pour la colonne actuelle\n",
    "        if feature_high_risk_coefficients:\n",
    "            high_risk_coefficients[feature_name] = feature_high_risk_coefficients\n",
    "\n",
    "    return high_risk_coefficients\n",
    "\n",
    "# Utilisation de la fonction pour calculer les coefficients de risque de haut risque\n",
    "risk_threshold = 70  # Modifier ce seuil selon votre critère de haut risque\n",
    "high_risk_coefficients = calculate_risk_coefficients(gb_clf, X_preprocessed_df, y_preprocessed_df, data_df, risk_threshold)\n",
    "\n",
    "# Afficher les résultats de haut risque uniquement\n",
    "print(\"=== Coefficient de risque de haut risque ===\")\n",
    "for feature_name, feature_values in high_risk_coefficients.items():\n",
    "    print(f\"=== Pour la colonne '{feature_name}' ===\")\n",
    "    for feature_value, risk_info in feature_values.items():\n",
    "        print(f\"Valeur: {feature_value} - Risque: {risk_info['risk_percentage']:.2f}% - Suggestion: {risk_info['risk_suggestion']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EW9c7hNujOYn",
    "outputId": "ef1af475-4af9-4c39-9cb3-7b61951b60ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La classe prédite est: RE\n",
      "Probabilités pour chaque classe:\n",
      "RE: 91.49%\n",
      "RF: 0.02%\n",
      "RM: 8.49%\n"
     ]
    }
   ],
   "source": [
    "def predict_risk_coefficient_with_proba(model, preprocess_pipeline, feature_dict):\n",
    "    # Convertir le dictionnaire en DataFrame\n",
    "    input_df = pd.DataFrame([feature_dict])\n",
    "\n",
    "    # Prétraiter les données\n",
    "    preprocessed_input = preprocess_pipeline.transform(input_df)\n",
    "\n",
    "    # Prédire les probabilités pour chaque classe\n",
    "    risk_probas = model.predict_proba(preprocessed_input)[0]\n",
    "\n",
    "    # Mapper les probabilités aux labels\n",
    "    risk_mapping = {'00': 'RE', '01': 'RF', '10': 'RM'}\n",
    "\n",
    "    # Convertir les labels des classes du modèle en chaînes binaires pour correspondre au mappage\n",
    "    class_labels = model.classes_.astype(str)  # Convertir les classes en chaînes\n",
    "    risk_percentages = {risk_mapping[class_labels[i]]: prob * 100 for i, prob in enumerate(risk_probas)}\n",
    "\n",
    "    # Déterminer la classe prédite\n",
    "    predicted_class_index = risk_probas.argmax()\n",
    "    predicted_risk = risk_mapping[class_labels[predicted_class_index]]\n",
    "\n",
    "    return predicted_risk, risk_percentages\n",
    "\n",
    "# Exemple d'utilisation\n",
    "feature_dict = {\n",
    "    'age': 83,\n",
    "    'nationality': 'Tunisie',\n",
    "    'gender': 'homme',\n",
    "    'Activites_label': 'AUTRES SERVICES',\n",
    "    'Produits': 'Prevoyance',\n",
    "    'Relation': 'Membre',\n",
    "    'Pays': 'TUNISIE',\n",
    "    'isPEP': False,\n",
    "    'famCode': 'V',\n",
    "    'VoieDeDistribution': 'Agences'\n",
    "}\n",
    "\n",
    "# Appel de la fonction pour prédire le coefficient de risque pour les caractéristiques fournies\n",
    "predicted_risk, risk_percentages = predict_risk_coefficient_with_proba(gb_clf, preprocessor, feature_dict)\n",
    "\n",
    "print(f\"La classe prédite est: {predicted_risk}\")\n",
    "print(\"Probabilités pour chaque classe:\")\n",
    "for risk, percentage in risk_percentages.items():\n",
    "    print(f\"{risk}: {percentage:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['models/risk_pipeline.pkl']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Supposons que tu as un préprocesseur nommé 'preprocessor' et ton modèle 'gb_clf'\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', gb_clf)\n",
    "])\n",
    "\n",
    "joblib.dump(pipeline, 'models/risk_pipeline.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
